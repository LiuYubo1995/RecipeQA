{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        return torch.mean(torch.mul(t, torch.log(a)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6319, -0.6664, -0.5437])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.mul(t, torch.log(a)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9750, -1.5585, -1.7730, -3.1625, -0.1940, -5.5974, -0.3315, -2.1483,\n",
       "         -0.4739, -0.0784],\n",
       "        [-0.1700, -0.2483, -1.6401, -0.3566, -1.9877, -1.4689, -0.8645, -1.0049,\n",
       "         -0.6914, -1.6756],\n",
       "        [-1.2668, -2.2273, -0.5321, -4.2795, -0.4893, -2.2367, -0.4924, -0.0929,\n",
       "         -0.0510, -0.3875]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2886, 0.2940, 0.2765, 0.7288, 0.7426, 0.3793, 0.1228, 0.0549, 0.7297,\n",
       "         0.1559],\n",
       "        [0.7995, 0.1139, 0.5442, 0.3043, 0.9156, 0.9088, 0.7655, 0.7015, 0.6062,\n",
       "         0.3333],\n",
       "        [0.0549, 0.5938, 0.1141, 0.6690, 0.9251, 0.1295, 0.0582, 0.8720, 0.3532,\n",
       "         0.6478]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6319, -0.6664, -0.5437])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = My_loss()\n",
    "loss(a, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.rand(10000, 50)\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Data.Dataset):\n",
    "    def __init__(self, x, y): # data_file='./data/train_cleaned.json'\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return x.size(0) # the number of recipe\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "\n",
    "        return x, y\n",
    "train_dataset = Dataset(x, y)\n",
    "\n",
    "loader_train = Data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1000, 5))\n",
    "y = torch.rand((1000, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 5])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 1166.78it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00, 708.14it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00, 456.40it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00, 542.32it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00, 607.43it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00, 361.55it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00, 588.51it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00, 481.94it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00, 426.77it/s]\u001b[A\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:00<00:00, 437.64it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111111\n",
      "1\n",
      "1\n",
      "tensor([-0.7396, -1.0744, -0.7594, -0.6501, -0.5862, -0.8437, -0.5587, -0.8116,\n",
      "        -0.8686, -0.9720], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-0.4667, -0.7469, -0.5833, -0.8065, -1.0641, -0.5098, -1.0482, -1.1021,\n",
      "        -0.7969, -0.6028], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-0.6776, -0.4535, -0.7708, -0.5008, -0.8904, -0.6562, -0.5002, -0.7810,\n",
      "        -0.3314, -0.6715], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-0.9549, -1.0405, -0.8768, -0.5017, -0.6543, -0.7489, -0.5847, -1.1185,\n",
      "        -1.0567, -0.5490], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-0.4656, -0.3402, -0.8577, -0.8516, -1.0856, -0.9446, -0.8404, -0.6807,\n",
      "        -0.8692, -0.9593], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-1.2990, -0.4388, -1.1263, -0.7994, -0.7343, -0.7996, -0.8482, -1.5455,\n",
      "        -0.6981, -1.1734], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-0.8045, -0.4630, -1.3481, -1.1954, -0.8186, -1.3516, -0.3810, -0.8084,\n",
      "        -0.8671, -1.2715], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-0.5272, -1.1564, -0.9248, -1.6656, -1.6820, -0.8598, -1.4498, -1.2614,\n",
      "        -1.7136, -2.1139], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-1.5677, -1.5024, -0.9817, -2.1563, -1.6822, -1.6001, -0.6766, -1.4891,\n",
      "        -1.5879, -1.5307], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-1.0324, -1.6545, -1.7988, -2.2702, -1.0647, -1.8251, -2.0840, -1.8032,\n",
      "        -2.6245, -1.4711], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-2.3604, -1.0876, -1.4060, -1.8970, -2.7548, -1.9842, -2.8046, -0.9963,\n",
      "        -3.4938, -2.2503], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-2.3615, -3.0935, -2.6087, -3.8651, -2.5654, -2.4906, -1.1009, -2.4017,\n",
      "        -2.6234, -2.2176], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-0.9583, -1.7393, -3.6689, -4.6680, -3.2611, -2.5740, -1.8419, -1.7041,\n",
      "        -2.0304, -4.8904], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-4.2344, -3.5786, -5.1850, -2.3854, -4.1036, -3.1233, -5.1400, -2.2819,\n",
      "        -1.8874, -0.6611], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-3.7567, -5.0313, -5.0718, -2.6798, -2.2739, -1.6019, -4.3238, -3.6903,\n",
      "        -3.4587, -2.9911], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-3.8863, -5.8426, -3.3871, -3.8577, -4.9258, -3.3345, -2.5139, -3.7863,\n",
      "        -3.7795, -3.1832], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-2.0214, -5.7527, -8.0025, -8.0157, -3.1258, -3.3717, -5.5704, -5.2183,\n",
      "        -5.6907, -6.3721], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-2.4956, -4.5345, -5.7057, -5.0208, -4.7153, -3.6023, -5.6486, -5.3779,\n",
      "        -3.9229, -4.1651], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-5.8529, -7.1198, -1.2120, -5.3398, -5.4310, -1.9270, -5.7307, -7.5232,\n",
      "        -5.3203, -4.9218], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-7.2159, -5.5660, -6.5921, -4.3168, -5.6660, -2.1305, -4.9406, -8.7639,\n",
      "        -4.8776, -7.5920], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-4.0698, -3.0303, -3.1247, -7.3187, -7.2529, -4.7750, -7.5001, -8.0003,\n",
      "        -7.3564, -7.7274], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([ -4.0457,  -5.5587,  -6.1095,  -1.9322,  -5.5188,  -7.1500,  -3.4389,\n",
      "         -8.6450, -11.4009,  -7.2946], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-5.6414, -7.0480, -9.8049, -2.9449, -8.1948, -6.7658, -6.8428, -9.3145,\n",
      "        -8.0053, -7.1302], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-9.2604, -6.9746, -6.2309, -5.8028, -4.8570, -6.7593, -5.8268, -8.3776,\n",
      "        -6.0420, -6.7910], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([ -9.2856, -11.8343,  -6.1776, -12.1358, -11.6245, -16.1648,  -3.8111,\n",
      "         -6.7954,  -8.9891,  -8.8873], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([ -4.5474, -12.9983,  -5.2657,  -4.1536,  -7.0660, -11.3047,  -5.5328,\n",
      "         -5.4313,  -8.5300,  -6.6149], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([ -9.0484,  -8.1426,  -5.4515, -13.0801,  -4.0247,  -7.9102, -12.6352,\n",
      "        -12.1972,  -9.4555, -15.1119], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([ -6.7620, -13.5325,  -6.3894, -11.5750, -12.8103,  -6.9724,  -8.3979,\n",
      "         -9.4899, -11.9498,  -2.6040], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-10.9801,  -9.8902,  -8.2626,  -8.6350,  -6.9833, -14.0254,  -5.6191,\n",
      "        -12.4906, -14.0768, -11.0647], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([ -6.3696, -10.3819,  -7.3880, -13.6650,  -2.3336,  -8.5215, -11.4245,\n",
      "         -7.8879,  -8.7243, -11.0961], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-19.4016,  -5.5734,  -9.3402,  -1.7327, -15.1178, -10.5231, -12.1291,\n",
      "         -7.6415,  -7.8583, -14.7741], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-12.8881, -18.5533, -10.0900, -13.1528, -15.6132, -13.7376,  -6.7819,\n",
      "         -6.9552, -12.9780, -16.3804], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-11.6358, -14.2068,  -5.0524, -12.3707, -19.4826, -12.0324, -15.2838,\n",
      "        -18.4504,  -3.3750, -18.6963], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-12.1897,  -9.3754, -17.6524, -15.4260, -12.1589, -13.0660,  -9.0771,\n",
      "        -28.0935, -14.0815, -16.7856], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([ -7.9929,  -9.3656, -15.3427,  -8.8530, -15.4894,  -6.1984,  -9.5802,\n",
      "        -15.6110, -22.1376, -10.4850], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-10.7430, -16.2854, -15.8238,  -4.4513, -18.5935, -18.8743, -15.0293,\n",
      "        -11.7495,  -9.9877,  -5.2240], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-13.6563,  -4.7261, -11.8692, -18.5554, -12.9423, -19.0462, -12.5078,\n",
      "         -8.7531,  -6.5479, -23.0562], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-12.9859, -18.2279,  -7.2385, -19.1364, -11.0408,  -8.0393, -15.6134,\n",
      "        -14.9990, -28.1294, -15.0610], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-16.0287, -23.4625, -14.2306, -13.4449, -17.3741, -28.1872, -14.3610,\n",
      "        -22.3366, -17.0936,  -7.3654], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([ -4.9776,  -7.5933, -15.2721, -21.7566, -12.5283, -13.3097, -11.2819,\n",
      "        -10.8976, -10.2679, -15.9977], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-10.2878, -10.9044, -19.1569, -13.3473, -18.8160,  -8.2950, -13.4777,\n",
      "        -15.2096, -21.4522, -15.5324], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-12.4768, -22.1749, -13.3966,  -7.9679, -23.8976, -23.9647,  -7.2453,\n",
      "        -21.7650, -20.7936, -18.6609], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-23.0321, -20.9563, -20.7474, -24.5841, -16.2123, -12.5006, -23.8028,\n",
      "        -25.3133, -18.7236, -14.0694], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-19.4112, -13.0434,  -7.9688, -23.0544, -17.0310,  -6.5902, -28.8076,\n",
      "        -14.9000, -12.0745,  -8.2995], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-26.8151, -19.0634, -22.1403, -18.7304, -29.5373, -28.4828, -23.6350,\n",
      "         -9.4679,  -6.8287, -11.7660], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-22.5360, -13.7968, -18.0004, -22.2280, -25.5007, -10.3668, -23.9470,\n",
      "        -11.4079, -17.0754, -23.1049], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-19.3266, -21.1654,  -8.5888, -16.5937, -24.3381, -13.4548, -19.4263,\n",
      "        -12.5161,  -5.4345, -25.4843], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-20.8685, -21.2614, -11.5023, -20.7000,  -7.4796, -16.5653, -18.4490,\n",
      "        -28.5739,  -6.9009, -19.3322], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-23.7845, -19.0119, -22.0739, -27.0570, -29.3588, -25.0993, -12.9777,\n",
      "        -18.7239, -19.0834,  -8.4413], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-19.1218, -16.2861, -19.0578,  -7.1431, -13.1329, -28.8222, -29.4704,\n",
      "        -13.6042, -21.4415, -35.8877], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-24.6074,  -6.8607, -17.0517, -22.4107, -19.4513, -10.4219, -21.8152,\n",
      "        -27.2603,  -2.8209, -29.5450], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-33.5448, -12.7592, -19.2642, -14.2488, -22.4041, -27.9275, -23.1772,\n",
      "        -25.9272, -30.1403, -26.6905], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([ -7.3033, -34.1685, -13.2739, -25.3492, -15.3253, -25.3172, -18.2269,\n",
      "        -29.4086, -16.7774, -11.4680], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-14.5743, -29.2656, -19.4176, -14.9852, -13.2586, -29.8035, -27.5145,\n",
      "        -21.1272, -19.5471, -25.9777], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-17.9123, -18.6883, -20.8387, -18.9424, -27.8396, -27.4166, -25.8921,\n",
      "        -32.7042, -12.2325, -17.8834], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-22.9516, -30.4422, -33.9625, -15.2771, -27.4871, -25.7779, -13.4869,\n",
      "        -23.9643, -23.2273,  -6.0217], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-29.0971,  -6.6954, -28.8552, -24.3505, -19.9513, -18.0496, -16.5344,\n",
      "        -19.2170, -24.1078, -26.7071], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-13.0633, -14.0179, -32.0371, -30.9344, -29.1374, -28.9528,  -8.3452,\n",
      "         -9.1976, -23.3602, -15.9859], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-21.4062, -30.2880, -33.5063, -34.4009, -18.7281, -20.1857, -23.1418,\n",
      "        -19.6464, -26.6972, -20.9081], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([ -4.0113, -18.5187, -32.7934, -30.1003,  -9.6576, -18.4526, -27.1297,\n",
      "        -37.5259, -17.6671, -18.0812], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-15.8230,  -5.9961, -26.5341, -45.6726, -19.6745, -14.6081, -41.6815,\n",
      "        -10.5107, -31.0446, -12.4170], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-16.2246, -35.0811, -30.2810, -27.6581, -15.4498, -13.4396, -20.7045,\n",
      "        -36.1119, -19.6422, -18.0250], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-32.1994, -27.3407,  -8.8746, -12.9268, -19.2620, -15.7915,  -8.8648,\n",
      "        -35.7959, -10.9745, -28.8649], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-16.8047, -27.6530, -17.2290, -21.5387, -20.0475, -37.6428, -29.3286,\n",
      "        -33.1480, -27.4902, -41.6424], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-21.5935, -18.8155, -20.5804, -32.3884, -33.1201, -18.0598,  -7.1159,\n",
      "         -7.6264, -10.3744, -43.5286], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-22.1721, -22.7656, -27.7604, -12.4131, -17.3948,  -7.6720, -18.9067,\n",
      "        -17.1154, -36.2483, -33.0433], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-19.0873, -31.3061, -38.5800, -31.8261, -27.3843, -33.8644, -19.5757,\n",
      "        -26.4470, -34.7834, -19.4098], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-20.5761, -33.1906, -34.1538, -21.7585, -27.3064, -20.9600, -24.3958,\n",
      "        -17.3520, -30.1136, -33.7726], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-20.3038, -11.8574, -20.8044, -40.1259, -20.5039, -24.0770, -43.3124,\n",
      "        -22.7068, -36.3569, -29.1876], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([-55.0731, -17.4413,  -6.4337, -39.2470, -28.9820, -16.5582, -34.4127,\n",
      "        -17.6367, -34.5738, -23.4658], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1111111\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1111111\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1111111\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1111111\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1111111\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1111111\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1111111\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1111111\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n",
      "1111111\n",
      "1\n",
      "1\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class Dataset(Data.Dataset):\n",
    "    def __init__(self, x, y): \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return x.size(0)\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        return x, y\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.lr = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lr(x)\n",
    "        return F.softmax(x, dim = 1)\n",
    "    \n",
    "class My_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(My_loss, self).__init__()\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        return torch.mean(torch.mul(target, torch.log(pred)), dim=1)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    batch_size = 10\n",
    "    num_epochs = 10\n",
    "    x = torch.rand((1000, 5))\n",
    "    y = torch.rand((1000, 4))\n",
    "    train_dataset = Dataset(x, y)\n",
    "    loader_train = Data.DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            )\n",
    "\n",
    "    logistic_model = LogisticRegression(5, 4)\n",
    "\n",
    "    criterion = My_loss()\n",
    "    optimizer = torch.optim.SGD(logistic_model.parameters(), lr=0.1, momentum=0)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('1111111')\n",
    "        epoch_acc_train = 0\n",
    "        epoch_loss_val = 0\n",
    "        epoch_acc_val = 0\n",
    "        logistic_model.train()\n",
    "        for x, y in tqdm(loader_train):\n",
    "            print(len(loader_train))\n",
    "            print(1)\n",
    "            out = logistic_model(x)\n",
    "            loss = criterion(out, y) \n",
    "            print(loss)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(torch.ones_like(loss))\n",
    "            optimizer.step() \n",
    "            epoch_loss_train = 0\n",
    "            epoch_loss_train += loss\n",
    "#             epoch_acc_train += acc\n",
    "\n",
    "\n",
    "#         model.eval()\n",
    "#         for x,y in tqdm(loader_val):\n",
    "#             with torch.no_grad(): \n",
    "#                 predictions = model(context, question, choice)\n",
    "#                 predictions = torch.cat(predictions, 0).view(-1, len(answer))\n",
    "#                 predictions = predictions.permute(1, 0)\n",
    "#                 if torch.cuda.is_available():\n",
    "#                     answer = answer.cuda()\n",
    "#                 loss = criterion(predictions, answer)\n",
    "#                 acc = accuracy(predictions, answer)\n",
    "#                 epoch_loss_val += loss.item() \n",
    "#                 epoch_acc_val += acc\n",
    "\n",
    "\n",
    "        train_loss = epoch_loss_train / len(loader_train)\n",
    "        train_acc = epoch_acc_train / len(loader_train)\n",
    "        #print(train_loss)\n",
    "#         valid_loss = epoch_loss_val / len(loader_val)\n",
    "#         valid_acc = epoch_acc_val / len(loader_val)\n",
    "\n",
    "\n",
    "#     w0, w1 = logistic_model.lr.weight[0]\n",
    "#     w0 = w0.item()\n",
    "#     w1 = w1.item()\n",
    "#     b = logistic_model.lr.bias.item()\n",
    "#     plot_x = np.arange(30, 100, 0.1)\n",
    "#     plot_y = (-w0 * plot_x - b) / w1\n",
    "#     plt.plot(plot_x, plot_y)\n",
    "\n",
    "#     x0 = list(filter(lambda x: x[-1] == 0.0, data))\n",
    "#     x1 = list(filter(lambda x: x[-1] == 1.0, data))\n",
    "#     plot_x0_0 = [i[0] for i in x0]\n",
    "#     plot_x0_1 = [i[1] for i in x0]\n",
    "#     plot_x1_0 = [i[0] for i in x1]\n",
    "#     plot_x1_1 = [i[1] for i in x1]\n",
    "\n",
    "#     plt.plot(plot_x0_0, plot_x0_1, 'ro', label='x_0')\n",
    "#     plt.plot(plot_x1_0, plot_x1_1, 'bo', label='x_1')\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.CrossEntropyLoss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function _VariableFunctions.log>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.7703)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(c*torch.log(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        return torch.mean(target*torch.log(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "creterion = My_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2137, -1.6215, -0.3366, -0.1553, -0.2416, -0.9506, -0.3500, -1.0011,\n",
       "        -0.1732, -0.9976])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2707)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(b*torch.log(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2971, 0.1976, 0.7142, 0.8562, 0.7854, 0.3865, 0.7047, 0.3675, 0.8410,\n",
       "        0.3688])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.LongTensor([7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3580)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import \n",
    "u = torch.ones(20)\n",
    "a_k  = torch.rand(3, 20)\n",
    "q = torch.rand(4, 3, 20)\n",
    "T = torch.rand(10,3,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(3,20)\n",
    "b = torch.rand(3,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3124, 0.1562, 0.5107, 0.8983, 0.0520, 0.7503, 0.5575, 0.6284, 0.0793,\n",
       "         0.9723, 0.8839, 0.0625, 0.0163, 0.1350, 0.0517, 0.7198, 0.2833, 0.8712,\n",
       "         0.4886, 0.1283],\n",
       "        [0.2357, 0.4346, 0.6345, 0.8440, 0.2384, 0.2974, 0.5055, 0.3357, 0.5334,\n",
       "         0.4898, 0.6077, 0.2050, 0.8579, 0.6610, 0.9336, 0.4482, 0.1368, 0.2885,\n",
       "         0.2795, 0.6843],\n",
       "        [0.0162, 0.8460, 0.2019, 0.2696, 0.3509, 0.3706, 0.5173, 0.4579, 0.3483,\n",
       "         0.4532, 0.2130, 0.8266, 0.4980, 0.1375, 0.8521, 0.5419, 0.9995, 0.1191,\n",
       "         0.3321, 0.7487]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4747, 0.8068, 0.1269, 0.0041, 0.8436, 0.7613, 0.2404, 0.1955, 0.2217,\n",
       "         0.7112, 0.7160, 0.7124, 0.7898, 0.4332, 0.5313, 0.8793, 0.9858, 0.3063,\n",
       "         0.2208, 0.3213],\n",
       "        [0.1009, 0.3222, 0.3646, 0.7552, 0.1746, 0.3904, 0.5170, 0.8248, 0.2023,\n",
       "         0.6988, 0.8936, 0.9775, 0.9586, 0.2687, 0.9081, 0.9683, 0.6263, 0.3742,\n",
       "         0.1440, 0.1255],\n",
       "        [0.1550, 0.9922, 0.2778, 0.8468, 0.5174, 0.1272, 0.9058, 0.9366, 0.8774,\n",
       "         0.6354, 0.2829, 0.5397, 0.1173, 0.9174, 0.8432, 0.8830, 0.7356, 0.0077,\n",
       "         0.2959, 0.1964]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.0282, 5.5236, 5.7154])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.mul(a,b), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class linear_attention(nn.Module):\n",
    "    def __init__(self, question_dim, vector_dim, attention_dim):\n",
    "        super(linear_attention, self).__init__()\n",
    "        self.fc1 = nn.Linear(question_dim, attention_dim)\n",
    "        self.fc2 = nn.Linear(vector_dim, attention_dim)\n",
    "        self.fc3 = nn.Linear(attention_dim, 1)\n",
    "    def forward(self, question, vector): \n",
    "        H = torch.tanh(self.fc1(question)+self.fc2(vector))\n",
    "        attention_score = F.softmax(self.fc3(H), dim=0)\n",
    "        x = torch.matmul(attention_score.permute(1,2,0), question.permute(1,0,2))\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(10,2,requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [torch.tensor([0.2552, 0.1840, 0.1202]), torch.tensor([0.2958, 0.5976, 0.2728]), torch.tensor([0.2336, 0.2327, 0.0548]), torch.tensor([ 0.4371, -0.0618,  0.4259])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2552,  0.1840,  0.1202,  0.2958],\n",
       "        [ 0.5976,  0.2728,  0.2336,  0.2327],\n",
       "        [ 0.0548,  0.4371, -0.0618,  0.4259]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(a, 0).view(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class alternating_co_attention(nn.Module):\n",
    "    def __init__(self, batch_size, question_dim, vector_dim, attention_dim):\n",
    "        '''\n",
    "        input \n",
    "        question(time_step, batch_size, dim)\n",
    "        context(time_step, batch_size, dim)\n",
    "        '''\n",
    "        super(alternating_co_attention, self).__init__()\n",
    "        self.g = torch.zeros(vector_dim)\n",
    "        self.question_g_attention = linear_attention(question_dim, vector_dim, attention_dim)\n",
    "        self.context_q_attention = linear_attention(question_dim, vector_dim, attention_dim)\n",
    "        self.question_c_attention = linear_attention(question_dim, vector_dim, attention_dim)\n",
    "    def forward(self, question, context):\n",
    "        temp_vector = self.question_g_attention(question, self.g)\n",
    "        c_vector = self.context_q_attention(context, temp_vector)\n",
    "        q_vector = self.question_c_attention(question, c_vector)\n",
    "        print(q_vector.size())\n",
    "        print(c_vector.size())\n",
    "        return q_vector, c_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n",
      "torch.Size([3, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4827, 0.6922, 0.4167, 0.6225, 0.6362, 0.6429, 0.7822, 0.5888, 0.3377,\n",
       "          0.5341, 0.4915, 0.3339, 0.5649, 0.3068, 0.5527, 0.3088, 0.6420, 0.2626,\n",
       "          0.4300, 0.4787],\n",
       "         [0.4182, 0.3589, 0.3640, 0.7535, 0.2928, 0.4933, 0.3928, 0.4734, 0.3181,\n",
       "          0.3022, 0.3632, 0.4339, 0.3391, 0.4615, 0.5991, 0.4541, 0.2787, 0.5443,\n",
       "          0.8725, 0.5172],\n",
       "         [0.4249, 0.5454, 0.3598, 0.3986, 0.1710, 0.7588, 0.6043, 0.3123, 0.3966,\n",
       "          0.5256, 0.7211, 0.4187, 0.3182, 0.3332, 0.4362, 0.6096, 0.6509, 0.5582,\n",
       "          0.2765, 0.5428]], grad_fn=<SqueezeBackward1>),\n",
       " tensor([[0.5088, 0.5281, 0.4568, 0.4724, 0.5017, 0.5946, 0.6394, 0.4605, 0.5893,\n",
       "          0.4954, 0.5282, 0.4316, 0.5278, 0.4574, 0.5113, 0.4480, 0.6675, 0.4005,\n",
       "          0.5157, 0.5951],\n",
       "         [0.1917, 0.4657, 0.3128, 0.4366, 0.4821, 0.4829, 0.3691, 0.5299, 0.6122,\n",
       "          0.5499, 0.5041, 0.3448, 0.6339, 0.4796, 0.4181, 0.4848, 0.4758, 0.4770,\n",
       "          0.3082, 0.4788],\n",
       "         [0.3844, 0.3582, 0.4318, 0.4873, 0.4235, 0.3136, 0.5480, 0.5028, 0.5585,\n",
       "          0.4403, 0.4047, 0.5528, 0.6366, 0.6647, 0.6083, 0.5825, 0.4673, 0.5160,\n",
       "          0.7017, 0.4188]], grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = alternating_co_attention(3,20,20,20)\n",
    "a(q,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from_file = open('validation_features_resnet50.json', 'r', encoding='utf8').read()\n",
    "images = json.loads(from_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "images['empty'] = [[0 for i in range(1000)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('validation_features_resnet50.json', 'w', encoding='utf8') as f:\n",
    "        json.dump(images, f, indent=4, ensure_ascii=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images['empty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from_file = open('train_cleaned.json', 'r', encoding='utf8').read()\n",
    "recipe = json.loads(from_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cleaned_data(file = 'train_cleaned.json'):\n",
    "    file = open(file, 'r', encoding='utf8').read()\n",
    "    recipe = json.loads(file) #json file contains data in str, convert str to dict\n",
    "    recipe_context = recipe['context']\n",
    "    recipe_answer = recipe['answer']\n",
    "    recipe_choice = recipe['choice']\n",
    "    recipe_question = recipe['question']\n",
    "    recipe_images = recipe['images']\n",
    "    return recipe_context, recipe_images, recipe_question, recipe_choice, recipe_answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_context, recipe_images, recipe_question, recipe_choice, recipe_answer = load_cleaned_data('train_cleaned.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = recipe_context[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['3 until 5 whole vanilla beans250 gram of vegetable glycerin food gradeevery 100 gram of vanilla beans have 35 until 40 of whole vanilla beans',\n",
       "  'scrape vanilla beans and get the seeds into vegetable glycerin',\n",
       "  'vanilla beans seed and vegetable glycerin',\n",
       "  'whole vanilla beans put in a bottle with seeds and vegetable glycerin'],\n",
       " ['there are many variants of borscht this is possibly one of the quickest and easy versions for it you will need\\ningredients\\n4 cups of chilled sliced beets two 16oz cans\\n1 12 cups of beet juice conveniently that is about the amount of juice that will be in the \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 canned beets\\n2 tbsp lemon juice\\n2 tbsp of sugar\\nsalt and pepper to taste\\nsour cream\\ntools\\nblender\\xa0\\ntbsp\\nglass measuring cup to prevent staining\\nnice serving bowls\\xa0\\ncan \\xa0opener',\n",
       "  'open and drain off the beets saveing the juice',\n",
       "  'place the drained beet in the blender along with\\xa0lemon juice and sugar',\n",
       "  'add the beet juice',\n",
       "  'cover blender and blend until smooth oh and do not open the blender while it is going to check consistence there is nothing beets would like better than to escape and change the color of your cabinets',\n",
       "  'place in bowls and garnish with a dollop of sour cream serve with salt and pepper to taste',\n",
       "  'borscht is nicely complemented with fresh dill or green onions at a little restaurant i use to go to it was served with a warm boiled potato\\nto chill the soup i cheated buy refrigerating the beet in the can before opening \\nalso i heard that you can skip putting in the lemon juice and let the soup set in your refrigerator for two or three days this allows it to sourer on its own i have not tried this myself so if you have let me know how that works\\xa0'],\n",
       " ['all you need to make pumpkin puree is one or more sugar pumpkin sugar pumpkins tend to be firmer less stringy and smaller than carving pumpkins you do not want to use a carving pumpkin due to its stringiness\\xa0\\nthe number of pumpkins you buy will all depend on how much puree you want to make a rough estimate is that one small sugar pumpkin will make the equivalent amount of puree as a 15 oz can\\xa0i decided to use two sugar pumpkins so i could make multiple pumpkin dishes with the puree\\xa0\\nthings will be much easier in the pumpkin puree world if you have or have access to a sharp knife a roasting oven safe pan a spoon and a blender or food processor\\xa0\\nnow is a great time to preheat your oven to 375f\\xa0',\n",
       "  'before cutting your pumpkin make sure you are using a sharp knife pumpkins and squash can be difficult to cut  having a sharp knife will make things easier and safer next remove the stem if there is one you can either twist it off with your hand or cut it off with a knife then cut your pumpkin in half from top to bottom not side to side\\xa0',\n",
       "  'to scoop out the pumpkin guts a metal spoon works great i tried using a large serving spoon at first and soon realized it was too big a regular metal spoon was perfect it is important that you scoop out all of the seeds and bad gunk see photo if you scrape too much you will start removing the good gunk see photo or the meat of the pumpkin that will become puree\\xa0\\nset the gunk aside if you want to take the extra steps to toast the seeds for tasty snacking if you do not  toss that gunk in the compost or feed it to your chickens or if you have a parrot they might enjoy some pumpkin goop for a sweet treat\\xa0',\n",
       "  'place your pumpkins face down in the ovensafe pan pumpkins do not really have faces not until they are jackolanterns anyway so make sure the inside of your pumpkin is down and the outer skin is facing up fill the pan with approximately 12 of water then cover the dish with foil and place in the oven which should be preheated to 375f\\xa0\\nthey can cook in the oven anywhere from 45 minutes to 15 hours set your timer to 45 minutes and check them they are done when a fork easily slides through the outer skin and the meat of the pumpkin feels very soft the outer skin will look a bit darker and shinier as well\\xa0\\nthe two pumpkins i used took 1 hour\\xa0\\nlet the cooked pumpkins cool until they are easy to handle before you move onto the next step 15  20 minutes should be sufficient\\xa0\\n\\xa0',\n",
       "  'using a spoon scrape out the cooked pumpkin if the pumpkins are cooked enough the meat of the pumpkin should pull away from the skin very easily discard the skin of the pumpkin compost chickens parrot etc and place the cooked pumpkin into a bowl or blender\\xa0',\n",
       "  'put the cooked pumpkin into the blender or mixer and let er rip because the pumpkin is relatively soft at this point it should not take too long you will know you are done blending when the puree is free of chunks\\xa0 now the pumpkin puree is complete and ready to use in whatever recipe you please\\xa0 some of my favorites are pumpkin cinnamon rolls pumpkin rice pudding pumpkin pie and pumpkin smoothies',\n",
       "  'remove any gunk from the seeds this can be very tedious once you are completely fed up with removing orange gunk from your pumpkin seeds give them a good rinse in a strainer place them into a clean bowl and toss them with a little olive oil and salt if you want to make a sweet snack i recommend adding some cinnamon and sugar you do not need a lot of salt and make sure all the seeds are lightly coated with oil you can always add more salt after toasting them\\xa0\\nturn the oven down to 325f and spread the seeds out on a baking sheet lined with foil the foil simply makes cleaning the pan really easy bake for 10 minutes then stir the seeds and spread back out bake for another 1015 minutes or until the seeds are a light golden brown\\xa0\\nthe inside of the seed pumpkin kernel actually cooks faster than the outside if you cook the seeds until the outside is dark brown the inside will be burnt and your seeds will not taste very good\\xa0\\nif you have the luxury of having two ovens this is a great step to do while your pumpkin is cooking\\n        ']]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "batch_size = 5 \n",
    "for i in range(0, len(recipe_context), batch_size):\n",
    "        train_images.append(recipe_images[i : i + batch_size]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transport_1_0_2_image(a):\n",
    "        max_step = 0\n",
    "        for i in a:\n",
    "            if max_step < len(i):\n",
    "                max_step = len(i)\n",
    "        new = []\n",
    "        for i in range(max_step):\n",
    "            step = []\n",
    "            for j in a:\n",
    "                if len(j) <= i:\n",
    "                    step.append(['empty'])\n",
    "                else:\n",
    "                    step.append(j[i])      \n",
    "            new.append(step)\n",
    "        return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_images[0]\n",
    "x = transport_1_0_2_image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['how-to-make-halal-vanilla-extract_1_0.jpg'],\n",
       "  ['how-to-make-cold-borscht_1_0.jpg'],\n",
       "  [],\n",
       "  ['purple-gnocchi-with-gorgonzola_1_0.jpg',\n",
       "   'purple-gnocchi-with-gorgonzola_1_1.jpg',\n",
       "   'purple-gnocchi-with-gorgonzola_1_2.jpg'],\n",
       "  ['cabbage-burger_1_0.jpg']],\n",
       " [['how-to-make-halal-vanilla-extract_2_0.jpg'],\n",
       "  ['how-to-make-cold-borscht_2_0.jpg',\n",
       "   'how-to-make-cold-borscht_2_1.jpg',\n",
       "   'how-to-make-cold-borscht_2_2.jpg'],\n",
       "  ['easy-handmade-pumpkin-puree_2_0.jpg',\n",
       "   'easy-handmade-pumpkin-puree_2_1.jpg'],\n",
       "  ['purple-gnocchi-with-gorgonzola_2_0.jpg'],\n",
       "  ['cabbage-burger_2_0.jpg']],\n",
       " [['how-to-make-halal-vanilla-extract_3_0.jpg'],\n",
       "  ['how-to-make-cold-borscht_3_0.jpg', 'how-to-make-cold-borscht_3_1.jpg'],\n",
       "  ['easy-handmade-pumpkin-puree_3_0.jpg',\n",
       "   'easy-handmade-pumpkin-puree_3_1.jpg',\n",
       "   'easy-handmade-pumpkin-puree_3_2.jpg'],\n",
       "  ['purple-gnocchi-with-gorgonzola_3_0.jpg',\n",
       "   'purple-gnocchi-with-gorgonzola_3_1.jpg',\n",
       "   'purple-gnocchi-with-gorgonzola_3_2.jpg',\n",
       "   'purple-gnocchi-with-gorgonzola_3_3.jpg',\n",
       "   'purple-gnocchi-with-gorgonzola_3_4.jpg',\n",
       "   'purple-gnocchi-with-gorgonzola_3_5.jpg'],\n",
       "  ['cabbage-burger_3_0.jpg']],\n",
       " [['how-to-make-halal-vanilla-extract_4_0.jpg'],\n",
       "  ['how-to-make-cold-borscht_4_0.jpg'],\n",
       "  ['easy-handmade-pumpkin-puree_4_0.jpg',\n",
       "   'easy-handmade-pumpkin-puree_4_1.jpg',\n",
       "   'easy-handmade-pumpkin-puree_4_2.jpg',\n",
       "   'easy-handmade-pumpkin-puree_4_3.jpg',\n",
       "   'easy-handmade-pumpkin-puree_4_4.jpg'],\n",
       "  ['purple-gnocchi-with-gorgonzola_4_0.jpg',\n",
       "   'purple-gnocchi-with-gorgonzola_4_1.jpg',\n",
       "   'purple-gnocchi-with-gorgonzola_4_2.jpg'],\n",
       "  ['cabbage-burger_4_0.jpg', 'cabbage-burger_4_1.jpg']],\n",
       " [['empty'],\n",
       "  ['how-to-make-cold-borscht_5_0.jpg', 'how-to-make-cold-borscht_5_1.jpg'],\n",
       "  ['easy-handmade-pumpkin-puree_5_0.jpg',\n",
       "   'easy-handmade-pumpkin-puree_5_1.jpg',\n",
       "   'easy-handmade-pumpkin-puree_5_2.jpg',\n",
       "   'easy-handmade-pumpkin-puree_5_3.jpg'],\n",
       "  ['purple-gnocchi-with-gorgonzola_5_0.jpg'],\n",
       "  ['cabbage-burger_5_0.jpg']],\n",
       " [['empty'],\n",
       "  ['how-to-make-cold-borscht_6_0.jpg', 'how-to-make-cold-borscht_6_1.jpg'],\n",
       "  ['easy-handmade-pumpkin-puree_6_0.jpg',\n",
       "   'easy-handmade-pumpkin-puree_6_1.jpg'],\n",
       "  ['empty'],\n",
       "  ['cabbage-burger_6_0.jpg', 'cabbage-burger_6_1.jpg']],\n",
       " [['empty'],\n",
       "  ['how-to-make-cold-borscht_7_0.jpg'],\n",
       "  ['easy-handmade-pumpkin-puree_7_0.jpg',\n",
       "   'easy-handmade-pumpkin-puree_7_1.jpg',\n",
       "   'easy-handmade-pumpkin-puree_7_2.jpg'],\n",
       "  ['empty'],\n",
       "  ['cabbage-burger_7_0.jpg']],\n",
       " [['empty'],\n",
       "  ['empty'],\n",
       "  ['empty'],\n",
       "  ['empty'],\n",
       "  ['cabbage-burger_8_0.jpg',\n",
       "   'cabbage-burger_8_1.jpg',\n",
       "   'cabbage-burger_8_2.jpg']],\n",
       " [['empty'], ['empty'], ['empty'], ['empty'], ['cabbage-burger_9_0.jpg']]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_image_features(batch_images, feature)\n",
    "    batch = []\n",
    "    for i in batch_images:\n",
    "        temp2 = []\n",
    "        for j in i:\n",
    "            temp = []\n",
    "            if len(j) == 0:\n",
    "                temp = np.zeros((1,1,1000)).tolist()\n",
    "            for z in j:\n",
    "                temp.append(feature[z])\n",
    "            temp2.append(np.sum(temp, axis = 0))\n",
    "        batch.append(temp2)\n",
    "    return batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "b = torch.FloatTensor(batch).squeeze(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 5, 1000])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
