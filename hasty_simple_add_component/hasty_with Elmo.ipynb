{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "import collections\n",
    "import smart_open\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from gensim.test.utils import get_tmpfile\n",
    "import numpy as np\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "def load_cleaned_data(file = 'train_cleaned.json'):\n",
    "    file = open(file, 'r', encoding='utf8').read()\n",
    "    recipe = json.loads(file) #json file contains data in str, convert str to dict\n",
    "    recipe_context = recipe['context']\n",
    "    recipe_answer = recipe['answer']\n",
    "    recipe_choice = recipe['choice']\n",
    "    recipe_question = recipe['question']\n",
    "    recipe_images = recipe['images']\n",
    "    return recipe_context, recipe_images, recipe_question, recipe_choice, recipe_answer \n",
    "def accuracy(preds, y):\n",
    "    preds = F.softmax(preds, dim=1)\n",
    "    correct = 0 \n",
    "    pred = preds.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    acc = correct/len(y)\n",
    "    return acc \n",
    "def seed_everything(seed=123):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_everything()\n",
    "\n",
    "recipe_context, recipe_images, recipe_question, recipe_choice, recipe_answer = load_cleaned_data('train_cleaned.json')\n",
    "recipe_context_valid, recipe_images_valid, recipe_question_valid, recipe_choice_valid, recipe_answer_valid = load_cleaned_data('val_cleaned.json')\n",
    "fname = get_tmpfile(\"/Users/LYB/Desktop/coursework/Msc-project/recipe_baseline/hasty_simple_baseline/my_doc2vec_model\")\n",
    "model = gensim.models.doc2vec.Doc2Vec.load(fname) \n",
    "print()\n",
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "elmo = Elmo(options_file, weight_file, 1, dropout=0.2, requires_grad = False)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [06:44<00:00,  2.26it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "choice = []\n",
    "for i in tqdm(range(len(recipe_choice_valid))):\n",
    "    temp = []\n",
    "    for j in range(len(recipe_choice_valid[i])):\n",
    "        a = gensim.utils.simple_preprocess(recipe_choice_valid[i][j]) \n",
    "        #a = re.sub(r\"[^a-zA-Z0-9]\",\" \", recipe_choice_valid[i][j]).lower().split()\n",
    "        if len(a) == 0:\n",
    "            a = ['0']\n",
    "        character_ids = batch_to_ids([a]) \n",
    "        b  = torch.sum(elmo(character_ids)['elmo_representations'][0], dim=1)\n",
    "        temp.append(b.detach().numpy())\n",
    "    choice.append(temp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 961/961 [03:47<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "question = []\n",
    "for i in recipe_question_valid:\n",
    "    question.append(gensim.utils.simple_preprocess(' '.join(i)))\n",
    "for i in tqdm(range(len(question))):\n",
    "    character_ids = batch_to_ids([question[i]])\n",
    "    question[i] = torch.sum(elmo(character_ids)['elmo_representations'][0], dim=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = torch.FloatTensor(choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(question)):\n",
    "    question[i] = question[i].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = torch.FloatTensor(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = choice.squeeze(2)\n",
    "question = question.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy 0.30697190426638915\n"
     ]
    }
   ],
   "source": [
    "def exponent_neg_manhattan_distance(x1, x2):\n",
    "        return torch.sum(torch.abs(x1 - x2), dim=1)\n",
    "def cosine_dot_distance(x1, x2):\n",
    "        return torch.sum(torch.mul(x1, x2), dim=1)\n",
    "def Infersent(x1, x2): \n",
    "        a = torch.nn.functional.cosine_similarity(x1, x2.expand(4, -1), dim=1)\n",
    "        b = torch.sum(torch.mul(x1, torch.abs(x1 - x2)), dim=1)\n",
    "        c = torch.sum(torch.mul(x1, x1 * x2),dim=1) \n",
    "        d = torch.matmul(x2, torch.abs(x1 - x2).permute(1, 0))\n",
    "        e = torch.matmul(x2, (x1 * x2).permute(1, 0))  \n",
    "        f = torch.sum(torch.mul(torch.abs(x1 - x2), x1 * x2), dim=1)\n",
    "        return a\n",
    "answer = [] \n",
    "for i in range(len(question)):\n",
    "    answer.append(Infersent(choice[i], question[i]).numpy())\n",
    "answer = torch.FloatTensor(answer) \n",
    "answer_valid = torch.LongTensor(recipe_answer_valid)\n",
    "acc_val = accuracy(answer, answer_valid)\n",
    "print('validation accuracy', acc_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
